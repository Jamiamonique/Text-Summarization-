{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "  return 1/ (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "def cost(predicted_y, actual_y, q):\n",
    "  costs = 1/q *np.sum(-actual_y * np.log(predicted_y) - (1-actual_y)* np.log(1-predicted_y))\n",
    "  return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: dont really need cost list if not going to use\n",
    "def logisticRegression(trainFeatures, trainLabels, learning_rate, epochs):\n",
    "  q, x = trainFeatures.shape  # x is the number of features and q is sample quantity\n",
    "  weights = np.zeros(x)  # initialize weights to 0\n",
    "  cost_list=[]  # cost list\n",
    "  for i in range(epochs):\n",
    "    predicted_y = np.dot(trainFeatures.toarray(), weights) # predicted y or y_hat\n",
    "    sig = sigmoid(predicted_y)  # sigmoid of predicted y\n",
    "    delta = sig - trainLabels  # prediction error\n",
    "    gradient = 1/q * np.dot(trainFeatures.toarray().T, delta)  # partial derivative of cost function\n",
    "    #intercept_gradient = np.mean(delta)  # calculates mean of prediction error\n",
    "    weights -=learning_rate * gradient  # update weights\n",
    "    costs = cost(sig,trainLabels, q)  # calculate cost\n",
    "    cost_list.append(costs)  # add cost to list\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The efficiency of this model is based on the training speed.\n",
      "The training speed is 90.66 seconds\n",
      "The accuracy of the Logisitc Regression model is 66.40%\n"
     ]
    }
   ],
   "source": [
    "# train set \n",
    "dataset_train = pd.read_csv('train_amazon.csv')\n",
    "dataset_train = dataset_train.sample(frac=0.05, random_state=45)\n",
    "features_train = dataset_train['text']\n",
    "trainLabels = dataset_train['label']\n",
    "trainLabels = np.array(trainLabels, dtype=np.float64)  \n",
    "\n",
    "# test set \n",
    "dataset_test = pd.read_csv('test_amazon.csv')\n",
    "dataset_test = dataset_test.sample(frac=0.05, random_state=45)\n",
    "features_test = dataset_test['text']\n",
    "testLabels = dataset_test['label']\n",
    "testLabels = np.array(dataset_test['label'], dtype=np.float64)\n",
    "\n",
    "# bag of words \n",
    "bog = CountVectorizer()\n",
    "trainFeatures = bog.fit_transform(features_train)\n",
    "testFeatures = bog.transform(features_test)\n",
    "\n",
    "# training\n",
    "start = time.time()\n",
    "weights = logisticRegression(trainFeatures, trainLabels, 0.01, 25)\n",
    "duration = time.time() - start\n",
    "# testing \n",
    "y_hat = np.round(sigmoid(np.dot(testFeatures.toarray(), weights)))\n",
    "\n",
    "# metrics\n",
    "accuracy = np.mean(y_hat==testLabels)*100\n",
    "print(f\"The efficiency of this model is based on the training speed.\\nThe training speed is {duration:.2f} seconds\")\n",
    "print(f\"The accuracy of the Logisitc Regression model is {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
